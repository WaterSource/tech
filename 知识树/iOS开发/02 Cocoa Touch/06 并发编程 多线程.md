## 并发编程 多线程

* 线程: 在进程中可以用线程去执行一些主进程之外的代码。
* 进程: 一个正在执行中的程序实体，可以产生多个线程。
* 任务: 一个抽象的概念，用于表示一系列需要完成的工作。

### 多线程

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g7aepqgdvcj30yg0h6goq.jpg)

* NSThread

	是控制线程执行的对象，需要维护线程的生命周期和线程的同步和互斥等。
	
* NSOperation

	是一个抽象类，不需要自己管理线程的生命周期和线程的同步和互斥。需要和NSOperationQueue一起使用。可以很方便的设置线程之间的依赖关系。

* GCD

### GCD和NSOperation的对比

* Operation是基于GCD的更高级封装，可以通过`underlyingQueue`把`operation`放入已有的`dispatch_queue`中；
* NSOperation更容易执行取消操作，任务之间的依赖关系，队列任务的优先级设置，可以通过KVO监控任务执行情况；
* GCD是C语言风格的API，Operation是面向对象风格；

### GCD

* Dispatch Queue: 用于维护任务的队列，可以接受任务(将一个任务加入某个队列)，然后在适当的时候执行队列的任务。
* Dispatch Sources: 允许我们把任务注册到系统事件上。
* Dispatch Groups: 可以把一系列任务加到一个组里，组里的每个任务都要等待整个组的所有任务结束之后才结束。
* Dispatch Semaphores: 信号量，实现并发控制，避免资源竞争。

#### 优势

* 用于多核的并行运算，系统底层自动利用更多的CPU内核
* 自动管理线程的生命周期

#### 任务和队列

【执行任务】有两种方式，“同步执行”和“异步执行”。主要区别在于是否等待队列的任务执行结束，是否具备开启新线程的能力。

* 同步执行(sync)
	
	* 在添加的任务执行结束之前，会一直等待，直到队列里面的任务完成之后再继续执行；
	* 只能在当前线程中执行任务，不具备开启新线程的能力；

* 异步执行(async)
	
	* 不会做等待，可以继续执行任务
	* 可以在新线程中执行任务，具备开启新线程的能力

【队列】有两种，“串行队列”和“并发队列”。主要区别在于执行顺序不同，开启线程不同。

* 串行队列(Serial)
	* 只开启一个线程，一个任务执行完毕之后，再执行下一个任务；
* 并发队列(Concurrent)
	* 可以开启多个线程，并且同时执行任务；
	* 并发队列的并发功能只在任务异步执行(dispatch_async)下才有效；

#### 创建队列

`dispatch_queue_create`方法来创建队列，涉及两个参数:

* 第一个参数表示队列的唯一标识符，可为空；
* 第二个参数识别是串行队列还是并发队列；

```
// 串行队列的创建方法
dispatch_queue_t queue = dispatch_queue_create("net.testQueue", DISPATCH_QUEUE_SERIAL);
dispatch_queue_t queue = dispatch_queue_create("net.testQueue", nil);

// 并行队列的创建方法
dispatch_queue_t queue = dispatch_queue_create("net.testQueue", DISPATCH_QUEUE_CONCURRENT);
```

`主队列 dispatch_get_main_queue()`是特殊的串行队列；

`全局并发队列 dispatch_get_global_queue`首个参数为队列优先级，一般使用`DISPATCH_QUEUE_PRIORITY_DEFAULT`；第二个参数暂时没用？

总结下来会存在6种任务和队列的组合方式

##### 在主线程环境下，这6种组合的情况

|区别|并发队列|串行队列|主队列|
|---|---|---|---|
|同步执行(sync)| 没有开启新线程，串行执行任务 | 没有开启新线程，串行执行任务 | 死锁卡住不执行 |
|异步执行(async)| 有开启新线程，并发执行任务 | 有开启新线程(1条)，串行执行任务 | 没有开启新线程，串行执行任务 |

##### 在并发队列中

|区别|【异步执行+并发队列】嵌套【同一个并发队列】|【同步执行+并发队列】嵌套【同一个并发队列】|
|---|---|---|
|同步执行(sync)| 没有开启新线程，串行执行任务 | 没有开启新线程，串行执行任务 |
|异步执行(async)| 有开启新线程，并发执行任务 | 有开启新线程，并发执行任务 |

##### 在串行队列中

|区别|【异步执行+串行队列】嵌套【同一个串行队列】|【同步执行+串行队列】嵌套【同一个串行队列】|
|---|---|---|
|同步执行(sync)| 死锁 | 死锁 |
|异步执行(async)| 有开启新线程(1条)，串行执行任务 | 有开启新线程(1条)，串行执行任务 |

#### 举例理解

假设现在有 5 个人要穿过一道门禁，这道门禁总共有 10 个入口，管理员可以决定同一时间打开几个入口，可以决定同一时间让一个人单独通过还是多个人一起通过。不过默认情况下，管理员只开启一个入口，且一个通道一次只能通过一个人。

- 这个故事里，人好比是 **任务**，管理员好比是 **系统**，入口则代表 **线程**。

	- 5 个人表示有 5 个任务，10 个入口代表 10 条线程。
	- **串行队列** 好比是 5 个人排成一支长队。
	- **并发队列** 好比是 5 个人排成多支队伍，比如 2 队，或者 3 队。
	- **同步执行任务** 好比是管理员只开启了一个入口（当前线程）。
	- **异步执行任务** 好比是管理员同时开启了多个入口（当前线程 + 新开的线程）。

- **『异步执行 + 并发队列』** 可以理解为：现在管理员开启了多个入口（比如 3 个入口），5 个人排成了多支队伍（比如 3 支队伍），这样这 5 个人就可以 3 个人同时一起穿过门禁了。


- **『同步执行 + 并发队列』** 可以理解为：现在管理员只开启了 1 个入口，5  个人排成了多支队伍。虽然这 5 个人排成了多支队伍，但是只开了 1 个入口啊，这 5 个人虽然都想快点过去，但是 1 个入口一次只能过 1 个人，所以大家就只好一个接一个走过去了，表现的结果就是：顺次通过入口。

### GCD 案例分析

#### 案例一
```
NSLog(@"1"); // 任务一
dispatch_sync(dispatch_get_main_queue(), ^{
	NSLog(@"2");	// 任务二
});
NSLog(@"3");	// 任务三
```

```
控制台输出
1
```

分析:
![](https://tva1.sinaimg.cn/large/006y8mN6gy1g91zqzqly3j30sg0l3abp.jpg)

#### 案例二

```
NSLog(@"1");	// 任务一
dispatch_sync(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0), ^{
	NSLog(@"2");	// 任务二
});
NSLog(@"3");	// 任务三
```
```
控制台输出
1
2
3
```

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g91zubamx3j30sg0p3tb8.jpg)

### 锁

#### 线程不安全

[iOS多线程到底不安全在哪里？](https://zhuanlan.zhihu.com/p/23998703)

指针Property指向的内存区域
这一类多线程的访问场景是我们很容易出错的地方，即使我们声明property为atomic，依然会出错。因为我们访问的不是property的指针区域，而是property所指向的内存区域。可以看如下代码：

```
@property (atomic, strong) NSString* stringA;

//thread A
for (int i = 0; i < 100000; i ++) {
    if (i % 2 == 0) {
        self.stringA = @"a very long string";
    }
    else {
        self.stringA = @"string";
    }
    NSLog(@"Thread A: %@\n", self.stringA);
}

//thread B
for (int i = 0; i < 100000; i ++) {
    if (self.stringA.length >= 10) {
        NSString* subStr = [self.stringA substringWithRange:NSMakeRange(0, 10)];
    }
    NSLog(@"Thread B: %@\n", self.stringA);
}
```

虽然stringA是atomic的property，而且在取substring的时候做了length判断,线程B还是很容易crash.

因为在前一刻读length的时候
`self.stringA = @"a very long string";`，

下一刻取substring的时候线程A已经将
`self.stringA = @"string";`，

立即出现out of bounds的Exception，crash，多线程不安全。

但加锁以后：

```
//thread A
[_lock lock];
for (int i = 0; i < 100000; i ++) {
    if (i % 2 == 0) {
        self.stringA = @"a very long string";
    }
    else {
        self.stringA = @"string";
    }
    NSLog(@"Thread A: %@\n", self.stringA);
}
[_lock unlock];

//thread B
[_lock lock];
if (self.stringA.length >= 10) {
    NSString* subStr = [self.stringA substringWithRange:NSMakeRange(0, 10)];
}
[_lock unlock];
```

整段代码就具有原子性了，就可以认为是多线程安全了。

####  `@synchronized`同步锁原理

通过汇编代码可以发现`@synchronized`会转变成

```
_objc_sync_enter
_objc_sync_exit
```

在OC源码中可以找到

```
// Begin synchronizing on 'obj'. 
// Allocates recursive mutex associated with 'obj' if needed.
// Returns OBJC_SYNC_SUCCESS once lock is acquired.  
int objc_sync_enter(id obj)
{
    int result = OBJC_SYNC_SUCCESS;

    if (obj) {
        SyncData* data = id2data(obj, ACQUIRE);
        assert(data);
        data->mutex.lock();
    } else {
        // @synchronized(nil) does nothing
        if (DebugNilSync) {
            _objc_inform("NIL SYNC DEBUG: @synchronized(nil); set a breakpoint on objc_sync_nil to debug");
        }
        objc_sync_nil();
    }

    return result;
}
```

```
// End synchronizing on 'obj'. 
// Returns OBJC_SYNC_SUCCESS or OBJC_SYNC_NOT_OWNING_THREAD_ERROR
int objc_sync_exit(id obj)
{
    int result = OBJC_SYNC_SUCCESS;

    if (obj) {
        SyncData* data = id2data(obj, RELEASE); 
        if (!data) {
            result = OBJC_SYNC_NOT_OWNING_THREAD_ERROR;
        } else {
            bool okay = data->mutex.tryUnlock();
            if (!okay) {
                result = OBJC_SYNC_NOT_OWNING_THREAD_ERROR;
            }
        }
    } else {
        // @synchronized(nil) does nothing
    }

    return result;
}
```

分析源码可以确定两个事情

* synchronized是用mutex做的递归锁
* synchronized(nil)不起作用

其中递归mutex可用下面这个例子来理解，下面这种实现并不会死锁

```
@synchronized(obj) {
	NSLog(@"1st sync");
	@synchronized(obj) {
		NSLog(@"2nd sync");
	}
}
```

##### 其中object的作用

`synchronized`中传入的object的内存地址，被用作key，通过`hash map`对应的一个系统维护的递归锁；

所以不管传入什么类型的object，只要是有内存地址，就能启动同步代码快的效果；

##### 慎用`@synchronized(self)`

因为`self`对象很可能被外部对象访问，两个公共锁交替使用的场景就容易出现死锁；

```
//class A
@synchronized (self) {
    [_sharedLock lock];
    NSLog(@"code in class A");
    [_sharedLock unlock];
}

//class B
[_sharedLock lock];
@synchronized (objectA) {
    NSLog(@"code in class B");
}
[_sharedLock unlock];
```

所以正确的做法是传入一个类内部维护的对象，而且这个对象对外不可见；

##### 粒度控制

有些人说`@synchronized`慢，但`@synchronized`和其他同步锁的性能相比并没有很夸张，对于使用者来说几乎忽略不计。

之所以慢是更多的因为没有做好粒度控制。锁本质上是为了让我们的一段代码获得原子性，不同的critical section要使用不同的锁。

```
@synchronized (sharedToken) {
    [arrA addObject:obj];
}

@synchronized (sharedToken) {
    [arrB addObject:obj];
}
```

使用同一个token来同步arrA和arrB的访问，虽然arrA和arrB之间没有任何联系。传入self的就更不对了。

应该是不同的数据使用不同的锁，尽量将粒度控制在最细的程度。上述代码应该是：

```
@synchronized (tokenA) {
    [arrA addObject:obj];
}

@synchronized (tokenB) {
    [arrB addObject:obj];
}
```

##### 注意避免代码块内部的函数调用

`@synchronized`还有个很容易变慢的场景，就是{}内部有其他隐蔽的函数调用。比如：

```
@synchronized (tokenA) {
    [arrA addObject:obj];
    [self doSomethingWithA:arrA];
}
```

doSomethingWithA内部可能又调用了其他函数，维护doSomethingWithA的工程师可能并没有意识到自己是被锁同步的，由此层层叠叠可能引入更多的函数调用，代码就莫名其妙的越来越慢了，感觉锁的性能差，其实是我们没用好。

所以在书写`@synchronized`内部代码的时候，要十分小心内部隐蔽的函数调用。